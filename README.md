# ü©∫ Pima Indians Diabetes ‚Äî Machine Learning Notebook

(1)Descri√ß√£o do Projeto
    Este projeto desenvolve um modelo de Machine Learning para prever a presen√ßa de diabetes em pacientes, utilizando o dataset "Pima Indians Diabetes Database". O principal classificador explorado √© o Support Vector Machine (SVM).

    O foco central do estudo √© a otimiza√ß√£o de hiperpar√¢metros atrav√©s do GridSearchCV, com uma an√°lise comparativa rigorosa entre duas estrat√©gias de valida√ß√£o cruzada: KFold(10) e StratifiedKFold(3). O objetivo √© demonstrar a import√¢ncia da estratifica√ß√£o em datasets com classes desbalanceadas para obter uma estimativa de performance mais confi√°vel e, consequentemente, um modelo final mais robusto.

(2)Metodologia
    O projeto foi estruturado seguindo as seguintes etapas:

        ‚úîÔ∏è Carga e Divis√£o dos Dados: O dataset foi carregado e dividido em conjuntos de treino (80%) e teste (20%). A divis√£o foi feita de forma estratificada para garantir que a propor√ß√£o de pacientes diab√©ticos e n√£o diab√©ticos fosse mantida em ambos os conjuntos.
        
        ‚úîÔ∏è Pipeline de Pr√©-processamento: Foi constru√≠do um Pipeline para automatizar o tratamento dos dados, incluindo:
        StandardScaler: Para padronizar as features, garantindo que todas tenham a mesma escala.
        
        ‚úîÔ∏è Otimiza√ß√£o e Compara√ß√£o com GridSearchCV: O GridSearchCV foi utilizado para testar exaustivamente diferentes combina√ß√µes de hiperpar√¢metros do SVM (kernel, C, gamma). Este processo foi executado duas vezes para comparar as seguintes estrat√©gias de valida√ß√£o:
        KFold com 10 splits: Uma valida√ß√£o cruzada padr√£o.
        StratifiedKFold com 3 splits: Uma valida√ß√£o que preserva a propor√ß√£o das classes em cada fold.
        
        ‚úîÔ∏è Treinamento e Avalia√ß√£o do Modelo Final: Ap√≥s a otimiza√ß√£o, o melhor conjunto de hiperpar√¢metros (kernel='rbf', C=10, gamma=0.01) foi usado para treinar um modelo final com todos os dados de treino. O desempenho deste modelo foi ent√£o avaliado no conjunto de teste, utilizando m√©tricas como acur√°cia, matriz de confus√£o e o classification_report (com precis√£o, recall e F1-score).
        
        ‚úîÔ∏è Visualiza√ß√£o da Fronteira de Decis√£o: Para uma an√°lise mais intuitiva, foi gerado um gr√°fico que plota a fronteira de decis√£o do modelo SVM, mostrando como ele separa os pacientes com base nas duas features mais relevantes (Glucose e BMI).

(3)Pr√©-requisitos e Instala√ß√£o
    A grande vantagem de usar o Google Colab √© que ele j√° vem com o ambiente pronto, simplificando muito a configura√ß√£o.

    Pr√©-requisitos:

        Google Colab;
        python.

    Bibliotecas:
            pandas;
            scikit-learn;
            Numpy;
            Matplotlib.

(4)Resultados e An√°lise
    A etapa de GridSearchCV revelou que a melhor combina√ß√£o de hiperpar√¢metros foi {'clf__kernel': 'rbf', 'clf__C': 10, 'clf__gamma': 0.01} para ambas as estrat√©gias de valida√ß√£o cruzada.

    O modelo final, treinado com estes par√¢metros, alcan√ßou uma acur√°cia de aproximadamente 75.32% no conjunto de teste. A an√°lise detalhada do classification_report mostra que o modelo possui um bom equil√≠brio entre precis√£o e recall, sendo o recall para a classe "diab√©tico" uma m√©trica de especial import√¢ncia cl√≠nica, pois indica a capacidade do modelo de identificar corretamente os pacientes que de fato possuem a doen√ßa.

    Matriz de Confus√£o
    A matriz de confus√£o ilustra a distribui√ß√£o de acertos e erros do modelo no conjunto de teste.

![matriz de confusao.png](matriz%20de%20confusao.png)

    Decis√£o do SVM
    o kernel RBF cria uma fronteira de decis√£o n√£o-linear para separar as classes, utilizando as features Glucose e BMI. Os pontos circulados representam os vetores de suporte, que s√£o os dados mais influentes para a defini√ß√£o do modelo.


(6)Ferramentas Utilizadas
        Linguagem: 
        Python 3

    Bibliotecas:
        Pandas;
        Numpy;
        Scikit-learn;
        Matplotlib.
